\chapter{Dangless - Implementation}
\label{ch:implementation}

\section{API overview}

Dangless is a Linux static library \texttt{libdangless.a} that can be linked to any application during build time. \todo{Probably should write about how to build it and how to link it to existing applications.} It defines a set of functions for allocating and deallocating memory:

\begin{lstlisting}
// sources/include/dangless/dangless_malloc.h

void *dangless_malloc(size_t sz) __attribute__((malloc));
void *dangless_calloc(size_t num, size_t size) __attribute__((malloc));
void *dangless_realloc(void *p, size_t new_size);
int dangless_posix_memalign(void **pp, size_t align, size_t size);
void dangless_free(void *p);
\end{lstlisting}

These functions have the exact same signature and behaviour as their standard counterparts \lstinline!malloc()!, \lstinline!calloc()!, and \lstinline!free()!. In fact, because the GNU C Library defines these standard functions as weak symbols~\cite{glibc-malloc-is-weak}, Dangless provides an option (\lstinline!CONFIG_OVERRIDE_SYMBOLS!) to override the symbols with its own implementation, enabling the user code to perform memory management without even being aware that it's using Dangless in the background.

Besides the above functions, Dangless defines a few more functions, out of which the following two are important.

\begin{lstlisting}
void dangless_init(void);
\end{lstlisting}

First, \lstinline!dangless_init()! initializes Dangless, and has to be called before any memory management is performed that Dangless should protect. The most important thing that this function does is initialize and enter Dune by calling \lstinline!dune_init()! and \lstinline!dune_enter()!. Dangless relies on Dune to be able to manipulate the page tables. Afterwards, we register our own pagefault handler with Dune, which enables us to detect when a memory access has failed due to the protection that Dangless offers.

By default, Dangless automatically registers this function in the \lstinline!.preinit_array! section of the binary, causing it to be called automatically before any user-defined constructors or the \lstinline!main()! entry point. This can be disabled via the \lstinline!CONFIG_REGISTER_PREINIT! option.

It's important to note that heap memory allocation can and does happen \emph{before} \lstinline!dangless_init()! is called, for example as part of the glibc runtime initialization. This case needs to be handled, so all of the \lstinline!dangless_! functions simply pass the call through to the underlying (system) allocator without doing anything else if they are called before \lstinline!dangless_init()!.

\begin{lstlisting}
int dangless_dedicate_vmem(void *start, void *end);
\end{lstlisting}

In order for Dangless to work, it requires exclusive use of some virtual memory to remap user allocations into. This region has to be large, as each \lstinline!dangless_malloc()! call will use up at least one page from it, and currently this virtual memory is never re-used because we lack a mechanism (such as a garbage collector) to be reasonably certain that a given virtual memory page is no longer referenced. This function can be used to make virtual memory regions available to Dangless for this purpose.

Since users of Dangless will typically not know or want to make this decision themselves, we provide the option \lstinline!CONFIG_AUTO_DEDICATE_MAX_PML4ES! which allows Dangless to take ownership of one or more unused PML4 pagetable entries which can each map 512 gigabytes of memory. This occurs at most once when a \lstinline!dangless_malloc()! or similar call is made, but Dangless does not have sufficient virtual memory available to it to protect the call.

This solution is very simplistic, and a smarter way to take ownership of virtual memory is decidedly possible. For instance, any time we require more virtual memory, we could scan the page tables and take ownership of some amount of currently-unused page table entries. Some implementation effort would need to be made to make sure this doesn't conflict with Dune's virtual memory allocation. However, this is very easy in the used Dune version, as Dune's page allocator (as defined in \texttt{libdune/dune.h}) uses maximum \lstinline!MAX_PAGES = (1 << 20)! pages (i.e. 4 GB of memory) starting at \lstinline!PAGEBASE = 0x200000000!. Any memory outside of this that is not used to hold application or kernel code or data is available for use by Dangless uncontested.

\section{Performing an allocation}

Whenever Dangless is asked to allocate some memory via a call to \lstinline!dangless_malloc()!, \lstinline!dangless_calloc()!, or \lstinline!dangless_realloc()!, a number of steps have to happen: physical memory has to be allocated, virtual memory has to be allocated, and the mapping created. Most of the process is the same regardless of the exact function called. The only exception is \lstinline!dangless_realloc()!, which I will detail later.

\subsection{Allocating physical memory}

The first step Dangelss has to perform is to acquire the physical memory it can use to satisfy the allocation. It does not currently defer allocating physical memory like kernels typically do, although in principle it could.
Since the goal of Dangless is only to provide security benefits, Dangless has no strategy of physical memory management unlike normal implementations. In fact, the way this is done ultimately does not matter for Dangless' purposes. Due to these reasons, Dangless delegates the responsibility of actually performing (physical) memory allocation to the memory allocator that was in place before Dangless "hijacked" the memory management function symbols.

Specifically, it uses \lstinline!dlsym(RTLD_NEXT, "malloc")! to determine the address of the original \lstinline!malloc()!, etc. functions. Then it simply calls these functions whenever it needs physical memory allocation done: primarily when the user code requests an allocation, but sometimes also for internal purposes, such as for keeping track of available virtual memory regions.

There is a caveat to using \lstinline!dlsym()!: when \lstinline!dlsym()! it is first called on a thread, it allocates a thread-specific buffer for holding a \lstinline!struct dl_action_result! object using \lstinline!calloc()!~\cite{glibc-dlsym-calls-calloc}. This means that without special handling for this case, execution can easily get into an infinite loop:

\begin{enumerate}
	\item User calls \lstinline!malloc()!, which is a strong alias of \lstinline!dangless_malloc()!
	\item \lstinline!dangless_malloc()! defers the physical memory allocation to the underlying allocator by calling \lstinline!sysmalloc()!
	\item \lstinline!sysmalloc()! does not yet have the address of the original \lstinline!malloc()! function, so it calls \lstinline!dlsym()! to get it
	\item \lstinline!dlsym()! notices it's running on this thread for the first time, so it calls \lstinline!calloc()! to allocate a buffer
	\item \lstinline!calloc()! is a strong alias of \lstinline!dangless_calloc()!, which calls \lstinline!syscalloc()! to allocate physical memory
	\item \lstinline!syscalloc()! does not yet have the address of the original \lstinline!calloc()! function, so it calls \lstinline!dlsym()!
	\item Repeat steps 4-6 forever...
\end{enumerate}

To get around this, \lstinline!syscalloc()! uses a static buffer of \lstinline!CONFIG_CALLOC_SPECIAL_BUFSIZE! size for the very first allocation. This allows \lstinline!dlsym()! to complete and populate the addresses of the original allocation functions, which are used normally for all subsequent calls. The same approach was used by other projects that implement their own memory allocator replacements~\cite{dlsym-calloc-special-ex1}.

Finally, when \lstinline!sysmalloc()!, etc. returns, we have a completed physical memory allocation. However, what is returned to us is a virtual memory address. We could perform a pagetable walk to find the corresponding physical memory address, but this is unnecessary, as the mapping provided by Dune is very simple, so it's sufficient to use Dune's \lstinline!dune_va_to_pa()! function from \texttt{libdune/dune.h} that is far cheaper computationally than a page-table walk.

The implementation of Dangless cannot handle the system allocator returning a (guest) virtual memory region that is backed by non-contiguous (guest) physical memory. This should not normally be a problem, unless Dangless is used together with code that implements the system calls used by memory allocators (usually \lstinline!brk()! and \lstinline!mmap()!).
Note that it does not matter whether the host physical memory is contiguous or not: any \lstinline!mmap()! (or \lstinline!brk()! for that matter) allocation is mapped into the guest memory contiguously. \todo{I think that's the case though, but I'm not totally sure. Check this? Note that the implementation can be fixed if necessary.}

\subsection{Allocating virtual memory}

Given a physical memory address of the user allocation, Dangless needs to allocate the same amount of virtual memory pages from the regions dedicated to it. Furthermore, we need to guarantee that these virtual memory addresses are only be used for exactly one allocation, and are never reused. For this purpose, Dangless employs a simple freelist-based span allocator. A freelist is simply a singly linked-list of \lstinline!vp_span! objects each representing a free span of virtual memory, ordered by their end address:

\begin{lstlisting}
struct vp_span {
	vaddr_t start;
	vaddr_t end;
	
	LIST_ENTRY(vp_span) freelist;
};

struct vp_freelist {
	LIST_HEAD(, vp_span) items;
};
\end{lstlisting}

(The NetBSD \texttt{queue.h}~\cite{netbsd-queue-ref} v1.68 is used for the linked list handling macros.)

When virtual memory is needed, the freelist is walked until a \lstinline!vp_span! object representing a region of sufficient size is found. When one is found, the allocated space is removed from the beginning of the span (by adjusting \lstinline!start!), and the span is deleted if it is now empty. If no such span is found, the allocation fails.

Note that in the current, simple implementation of the virtual memory allocator there is only a single freelist, which is sufficient because we do not ever re-use any virtual memory. If we were to add a garbage collector-like solution, then this approach would likely lead to significant fragmentation with a negative performance impact on each allocation. In this situation, a possible enhancement would be to have several independent freelists of different page sizes, similar to common memory allocator designs. Other improvements are also possible: memory allocation is a well-understood problem.

\subsection{Remapping}

Now that Dangless has the physical memory address and a brand new virtual memory address, all that is left to do is mapping the virtual memory to the physical memory by modify the guest page tables. In a normal Linux userland application, this would not be possible to do directly or cheaply without implementing a Linux kernel module. Dune makes it possible for us to do this, as inside the virtualized environment, we have ring 0 privileges, so we can read control register 3 (\lstinline!cr3!) containing the (guest) physical address of the page table root. Thanks to the \texttt{dune-ix-guestppages.patch} patch to Dune, the host memory pages used to hold the guest's page tables are mapped into the guest virtual memory, allowing us to manipulate them during runtime from inside the guest.

Should the physical memory allocation fail, the machine is out of memory, and Dangless can do little but pass on this failure to the caller.

We have a different situation however if it's the virtual memory allocation that fails. I have already talked about Dangless' ability to automatically acquire virtual memory for its allocator by scanning the page table and taking unused PML4 entries for its own use. If even despite this mechanism Dangless does not have sufficient virtual memory to protect the user allocation by remapping it, then Dangless gives up. If the \lstinline!CONFIG_ALLOW_SYSMALLOC_FALLBACK! option is enabled, then Dangless simply forwards all later memory management function calls to the system allocator, to ensure that the user application keeps functioning. Otherwise, it exits the application.

\subsection{Handling realloc}

\lstinline!dangless_realloc()! requires some more sophisticated logic, as the behaviour of \lstinline!realloc()! is more complicated. \todo{Finish}

\section{Fixing up vmcalls}

\todo{section}

\section{Dune}

\todo{What is Dune, which version of Dune is used and why, and the patches applied}

\todo{This should probably be earlier in the chapter (or maybe in Background?)}
\todo{Also have to write about the requirements of Dangless and how to build it}

\section{Rumprun}

\todo{Development started on rumprun, why did I end up dropping it?}
