\chapter{Evaluation}

\section{Performance on SPEC 2006}

All measurements were made on Intel Core i7-4510U CPU @ 2.00GHz with 16 GB RAM, running Ubuntu 14.04 LTS, with Linux kernel version 4.4.0-161. Performance overhead was measured on the standard SPEC2006 benchmarking suite using the VUSec group's \texttt{instrumentation-infra} framework~\cite{vusec-infra}.

Dangless was built and configured in the following manner:

\begin{lstlisting}[breaklines, language=bash, style=]
./setup.py build \
	--dangless-config ALLOW_SYSMALLOC_FALLBACK=Off \
	--dangless-config COLLECT_STATISTICS=Off \
	--dangless-config ENABLE_PERF_EVENTS=Off \
	--dangless-config REPORT_RUSAGE=Off \
	--dangless-config SYSCALLMETA_HAS_INFO=Off \
	--targets spec2006 \
	--instances baseline dune-only dangless-malloc
\end{lstlisting}

This builds SPEC2006 in three configurations (referred to as ``instances''):
\begin{enumerate}
	\item \emph{baseline}: plain, unmodified benchmarks.
	\item \emph{dune-only}: all benchmarks are built linking to \path{libdune}, as well as a small utility library ensuring that Dune is entered automatically at program startup (\path{libdune-autoenter}). This is used to measure the overhead of Dune itself compared to \emph{baseline}.
	\item \emph{dangless-malloc}: linking to \path{libdangless-malloc} and its dependencies, measuring the overhead of Dangless itself.
\end{enumerate}

The above command line corresponds to building Dangless manually like so:

\begin{lstlisting}[breaklines, language=bash, style=]
cmake \
	-D CMAKE_BUILD_TYPE=RelWithDebInfo \
	-D ALLOW_SYSMALLOC_FALLBACK=Off \
	-D COLLECT_STATISTICS=Off \
	-D ENABLE_PERF_EVENTS=Off \
	-D REPORT_RUSAGE=Off \
	-D SYSCALLMETA_HAS_INFO=Off \
	..

cmake --build .
\end{lstlisting}

Finally, the benchmarks were run using the command:

\begin{lstlisting}[breaklines, language=bash, style=]
./setup.py run \
	--parallel=proc \
	--parallelmax=1 \
	--iterations=5 \
	spec2006 \
	baseline \
	dune-only \
	dangless-malloc \
	--benchmarks all_c all_cpp
\end{lstlisting}

This runs all of the C and C++ SPEC2006 benchmarks in all three configurations, sequentially (\texttt{parallelmax=1}), 5 times each.

Dangless successfully runs on all C and C++ benchmarks with following exceptions:

\begin{itemize}
	\item \path{400.perlbench} with test workload fails due to using the unsupported \lstinline!clone()! system call
	\item \path{400.perlbench} and \path{471.omnetpp} with reference workload both fail in very similar circumstances, indicating an EPT violation error. It is not clear what the cause is, but I suspect it is some limitation or bug in Dune.
\end{itemize}

\todo{So both benchmarks in ref workload fail with GPA = GVA = 0x2801ff000. Dune's PAGEBASE starts at 0x200000000. Does it maybe get overwritten after heap allocations? Test it!}

The performance overhead results are summarized in Table~\ref{tab:perf-dune-dangless-oscar} and visualized in Figure~\ref{fig:perf-dune-dangless-oscar}. Memory overhead results are summarized in Table~\ref{tab:mem-dune-dangless-oscar} and visualized in Figure~\ref{fig:mem-dune-dangless-oscar}. For comparison, I have included the overheads from Oscar~\cite{oscar2017}, which represents the current state of the art. Because unfortunately they have not published the exact numbers, these are estimations based on their included graphs.

% Performance overhead: Dune vs Dangless vs Oscar
\begin{table}[]
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{Benchmark} & \textbf{Dune} & \textbf{Dangless} & \textbf{Oscar} \\ \hline
		401.bzip2          & 0.995         & 1.013             & 1.000                      \\ \hline
		403.gcc            & 0.987         & 1.152             & 1.250                      \\ \hline
		429.mcf            & 1.003         & 1.115             & 1.000                      \\ \hline
		433.milc           & 1.039         & 1.107             & 1.055                      \\ \hline
		444.namd           & 1.000         & 1.004             & 1.000                      \\ \hline
		445.gobmk          & 1.001         & 1.025             & 1.005                      \\ \hline
		447.dealII         & 1.008         & 1.074             & 2.900                      \\ \hline
		450.soplex         & 1.004         & 1.030             & 1.040                      \\ \hline
		453.povray         & 1.003         & 0.997             & 1.050                      \\ \hline
		456.hmmer          & 1.023         & 1.023             & 1.007                      \\ \hline
		458.sjeng          & 0.999         & 1.011             & 1.010                      \\ \hline
		462.libquantum     & 0.993         & 0.995             & 1.025                      \\ \hline
		464.h264ref        & 1.001         & 0.997             & 1.045                      \\ \hline
		470.lbm            & 0.997         & 1.003             & 1.000                      \\ \hline
		473.astar          & 1.013         & 1.246             & 1.400                      \\ \hline
		482.sphinx3        & 1.012         & 1.030             & 1.080                      \\ \hline
		483.xalancbmk      & 1.018         & 1.198             & 4.050                      \\ \hline
	\end{tabular}
	\caption{Runtime performance overhead measurements: Dune, Dangless, and Oscar. A value of 1.0 indicates no performance overhead. Note that some values are below that in the Dune and Dangless instances: these should be considered measurement errors.}
	\label{tab:perf-dune-dangless-oscar}
\end{table}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
            scale only axis, % width and height only for the contents, not labels
            width=\textwidth,
            %height=0.65\paperheight,
            xtick=data,
            xticklabels from table={data/perf_vs_oscar.dat}{benchmark},
            xticklabel style={rotate=90},
            yticklabel={\pgfmathparse{\tick*100}\pgfmathprintnumber{\pgfmathresult}\%},
            ymin=0,
            ymax=0.5,
            point meta={y*100},
            %nodes near coords={\pgfmathprintnumber\pgfplotspointmeta\%},
            %nodes near coords align={horizontal},
            bar width=4pt,
            ymajorgrids=true,
            legend style={
                at={(0.15,0.975)},
                anchor=north,
                %legend columns=-1
            },
        ]
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dune} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dangless} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{oscar_estm} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            \legend{Dune only, Dangless, Oscar}
        \end{axis}
    \end{tikzpicture}
    \label{fig:perf-dune-dangless-oscar}
    \caption{Dune vs Dangless vs Oscar: performance overhead}
\end{figure}

% Memory overhead: Dune vs Dangless vs Oscar
\begin{table}[]
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		\textbf{Benchmark} & \textbf{Dune} & \textbf{Dangless} & \textbf{Oscar} \\ \hline
		401.bzip2          & 1.000         & 1.001             & 1.000          \\ \hline
		403.gcc            & 1.000         & 1.005             & 1.050          \\ \hline
		429.mcf            & 1.000         & 1.000             & 1.000          \\ \hline
		433.milc           & 1.000         & 1.002             & 1.180          \\ \hline
		444.namd           & 1.007         & 1.022             & 1.010          \\ \hline
		445.gobmk          & 1.010         & 1.030             & 1.000          \\ \hline
		447.dealII         & 1.000         & 1.512             & 5.100          \\ \hline
		450.soplex         & 1.000         & 1.000             & 1.720          \\ \hline
		453.povray         & 1.000         & 1.119             & 1.400          \\ \hline
		456.hmmer          & 1.004         & 1.034             & 1.350          \\ \hline
		458.sjeng          & 1.001         & 1.004             & 1.000          \\ \hline
		462.libquantum     & 1.002         & 1.010             & 1.040          \\ \hline
		464.h264ref        & 1.001         & 1.014             & 1.100          \\ \hline
		470.lbm            & 1.001         & 1.002             & 1.000          \\ \hline
		473.astar          & 1.000         & 1.003             & 1.450          \\ \hline
		482.sphinx3        & 1.008         & 1.033             & 5.000          \\ \hline
		483.xalancbmk      & 1.000         & 1.942             & 2.800          \\ \hline
	\end{tabular}
	\caption{Memory overhead measurements: Dune, Dangless, and Oscar. A value of 1.0 indicates no performance overhead.}
	\label{tab:mem-dune-dangless-oscar}
\end{table}

% Memory overhead: Dune vs Dangless vs Oscar
\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
            scale only axis, % width and height only for the contents, not labels
            width=\textwidth,
            %height=0.65\paperheight,
            xtick=data,
            xticklabels from table={data/mem_vs_oscar.dat}{benchmark},
            xticklabel style={rotate=90},
            yticklabel={\pgfmathparse{\tick*100}\pgfmathprintnumber{\pgfmathresult}\%},
            ymin=0,
            ymax=1.5,
            point meta={y*100},
            %nodes near coords={\pgfmathprintnumber\pgfplotspointmeta\%},
            %nodes near coords align={horizontal},
            bar width=4pt,
            ymajorgrids=true,
            legend style={
                at={(0.15,0.975)},
                anchor=north,
                %legend columns=-1
            },
        ]
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dune} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dangless} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{oscar_estm} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            \legend{Dune only, Dangless, Oscar}
        \end{axis}
    \end{tikzpicture}
    \label{fig:mem-dune-dangless-oscar}
    \caption{Dune vs Dangless vs Oscar: memory overhead}
\end{figure}

\todo{Why are there overhead values with Dune and Dangless that are less than 1.0??}
\todo{Explain the overheads. For this, we should probably log allocations in the benchmarks: their number and frequency. Maybe get information from TLB misses? I think we should already have that somewhere.}

Performance overhead comes from:
- Dangless just does more work per allocation/deallocation (e.g. page table walks and having to allocate page tables)
- additional TLB pressure and misses (since every allocation has a unique address)
- the overhead posed by Dune (virtualization, especially for vmcalls)

\section{Summary of contributions}

Dangless Malloc demonstrates the power of process-level, hardware-assisted virtualization and its use for hardening processes against bugs and malicious users without having to pay the usual performance penalties. This makes the approach of creating and destroying shadow virtual pages, used by previous work such as Oscar~\cite{oscar2017}, noticeably cheaper, without making the design significantly more complex.

Specifically, by running the process in a virtualized environment, Dangless does not have to perform a system call for managing the remapped (shadow) virtual memory, being able to manipulate the (guest) page tables directly -- at the minor cost of having to pass all normal system calls to the host kernel as measured by the original Dune research paper~\cite{dune-paper}.

Because these extra virtual memory mappings only exist in the guest system, the hosting Linux kernel is not aware of them, and does not have to maintain a \lstinline!vm_area_struct! structure for each of them -- something that is a source of significant overhead in similar approaches~\cite{oscar2017}. This comes at the cost of having to ``fix-up'' remapped pointers in system call arguments before they can be passed on the host kernel, but in practice this was not found to have noticeable performance implications.

Finally, Dangless does not have to store the canonical memory address of each allocation, because the virtual memory layout of Dune is very simple and predictable, allowing us to compute the canonical virtual addresses based on the physical ones. This does add the overhead of a single page walk to determine the physical memory address for every allocation management operation such as \lstinline!realloc()! and \lstinline!free()!, but the cost of these is insignificant compared to cost of prior approaches. Therefore, the only memory overhead posed by Dangless is the extra page tables used to encode these virtual memory mappings.

\section{Limitations and improvement opportunities}

Dangless Malloc was created as a proof of concept, and its implementation could be improved in various ways.

For instance, the \lstinline!realloc()! implementation is not optimal: even if the system allocator was unable to perform an in-place reallocation, we could still potentially do so with the remapped pages, if the virtual memory region following them is available. Care should only be taken to modify the page table entry of each of the old virtual page mappings to point to the new physical addresses.

Similarly, there's no real reason why Dangless is currently unable to handle the system allocator returning a virtual memory region that is not backed by contiguous guest physical memory.

As discussed earlier, Dangless could be smarter about its virtual memory auto-dedication logic, for example by acquiring unused virtual memory regions on-demand. We could also be using hugepages for the shadow virtual memory when the allocation size is greater than 2 MB or 1 GB.

In order to make it easier to incorporate Dangless into projects, it should support installation and exporting its CMake targets.

Major improvement opportunities would be supporting multi-threaded applications, after investigating Dune's state of support for it, and supporting the \lstinline!clone()! system call.

Finally, some mechanism for reclaiming virtual memory once we can reasonably guarantee the absence of pointers to them would ensure that we never run out of virtual memory even in long-running applications such as web servers.

\section{Conclusion}

\todo{...}
