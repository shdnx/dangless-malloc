% Tables generated by the awesome https://www.tablesgenerator.com/latex_tables -- thanks Roy for recommending it!

\chapter{Evaluation}

\section{Setup}

All measurements were made on Intel Core i7-4510U CPU @ 2.00GHz with 16 GB RAM, running Ubuntu 14.04 LTS, with Linux kernel version 4.4.0-161. Performance overhead was measured on the standard SPEC2006 benchmarking suite using the VUSec group's \texttt{instrumentation-infra} framework~\cite{vusec-infra}.

Dangless was built and configured in the following manner:

\begin{lstlisting}[breaklines, language=bash, style=]
./setup.py build \
	--dangless-config ALLOW_SYSMALLOC_FALLBACK=Off \
	--dangless-config COLLECT_STATISTICS=Off \
	--dangless-config ENABLE_PERF_EVENTS=Off \
	--dangless-config REPORT_RUSAGE=Off \
	--dangless-config SYSCALLMETA_HAS_INFO=Off \
	--targets spec2006 \
	--instances baseline dune-only dangless-malloc
\end{lstlisting}

This builds SPEC2006 in three configurations (referred to as ``instances''):
\begin{enumerate}
	\item \emph{baseline}: plain, unmodified benchmarks.
	\item \emph{dune-only}: all benchmarks are built linking to \path{libdune}, as well as a small utility library ensuring that Dune is entered automatically at program startup (\path{libdune-autoenter}). This is used to measure the overhead of Dune itself compared to \emph{baseline}.
	\item \emph{dangless-malloc}: linking to \path{libdangless-malloc} and its dependencies, measuring the overhead of Dangless itself.
\end{enumerate}

The above command line corresponds to building Dangless manually like so:

\begin{lstlisting}[breaklines, language=bash, style=]
cmake \
	-D CMAKE_BUILD_TYPE=RelWithDebInfo \
	-D ALLOW_SYSMALLOC_FALLBACK=Off \
	-D COLLECT_STATISTICS=Off \
	-D ENABLE_PERF_EVENTS=Off \
	-D REPORT_RUSAGE=Off \
	-D SYSCALLMETA_HAS_INFO=Off \
	..

cmake --build .
\end{lstlisting}

Finally, the benchmarks were run using the command:

\begin{lstlisting}[breaklines, language=bash, style=]
./setup.py run \
	--parallel=proc \
	--parallelmax=1 \
	--iterations=5 \
	spec2006 \
	baseline \
	dune-only \
	dangless-malloc \
	--benchmarks all_c all_cpp
\end{lstlisting}

This runs all of the C and C++ SPEC2006 benchmarks in all three configurations, sequentially (\texttt{parallelmax=1}), 5 times each.
% (Benchmarks not written in C or C++ were excluded, because they use their own memory allocators that are usually not based on top of the C API, rendering Dangless inapplicable for them.)

\section{Performance overhead on SPEC2006}

Dangless successfully runs on all C and C++ benchmarks with following exceptions:

\begin{itemize}
	\item \path{400.perlbench} with test workload fails due to using the unsupported \lstinline!clone()! system call
	\item \path{400.perlbench} and \path{471.omnetpp} with reference workload both fail in very similar circumstances, indicating an EPT violation error. It is not clear what the cause is, but I suspect it is some limitation or bug in Dune.
\end{itemize}

The performance overhead results are summarized in Table~\ref{tab:perf-dune-dangless-oscar} and visualized in Figure~\ref{fig:perf-dune-dangless-oscar}. Memory overhead results are summarized in Table~\ref{tab:mem-dune-dangless-oscar} and visualized in Figure~\ref{fig:mem-dune-dangless-oscar}.

For comparison with Dangless, I have included the overheads from Oscar~\cite{oscar2017}, which represents the current state of the art with overheads that are lower than that of previous technologies. Unfortunately, they have not published the exact numbers, so the values I reported for them are estimations based on their graphs.

The overhead values of Dune were measured together with those of Dangless, and correspond to the \texttt{dune-only} instance configured earlier. These numbers confirm the findings of the Dune paper~\cite{dune-paper}, in which they indicated insignificant performance overhead. Dune is therefore a promising technology to base further protections on.

% Performance overhead: Dune vs Dangless vs Oscar
\begin{table}[]
	\centering
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Benchmark} & \textbf{Dune} & \textbf{Dangless} & \textbf{Oscar} \\ \hline
		401.bzip2          & 0\%         & 1.3\%             & 0\%                      \\ \hline
		403.gcc            & 0\%         & 15.2\%             & {\color{orange} 25.0\%}                      \\ \hline
		429.mcf            & 0.3\%         & 11.5\%             & 0\%                      \\ \hline
		433.milc           & 3.9\%         & 10.7\%             & 5.5\%                      \\ \hline
		444.namd           & 0\%         & 0.4\%             & 0\%                      \\ \hline
		445.gobmk          & 0.1\%         & 2.5\%             & 0.5\%                      \\ \hline
		447.dealII         & 0.8\%         & 7.4\%             & {\color{red} 190.0\%}                      \\ \hline
		450.soplex         & 0.4\%         & 3.0\%             & 4.0\%                      \\ \hline
		453.povray         & 0.3\%         & 0\%             & 5.0\%                      \\ \hline
		456.hmmer          & 2.3\%         & 2.3\%             & 0.7\%                      \\ \hline
		458.sjeng          & 0\%         & 1.1\%             & 1.0\%                      \\ \hline
		462.libquantum     & 0\%         & 0\%             & 2.5\%                      \\ \hline
		464.h264ref        & 0.1\%         & 0\%             & 4.5\%                      \\ \hline
		470.lbm            & 0\%         & 0.3\%             & 0\%                      \\ \hline
		473.astar          & 1.3\%         & {\color{orange} 24.6\%}             & {\color{orange} 40.0\%}                      \\ \hline
		482.sphinx3        & 1.2\%         & 3.0\%             & 8.0\%                      \\ \hline
		483.xalancbmk      & 1.8\%         & {\color{orange} 19.8\%}             & {\color{red} 305.0\%}                      \\ \hline
	\end{tabular}
	\caption{Runtime performance overhead measurements: Dune, Dangless, and Oscar. A value of 0\% indicates no overhead, while a value of 100\% means that runtime was double that of baseline. Overhead values of 20\% or higher were highlighted in \textcolor{orange}{orange}, while over 100\% are in \textcolor{red}{red}.}
	\label{tab:perf-dune-dangless-oscar}
\end{table}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
            scale only axis, % width and height only for the contents, not labels
            width=\textwidth,
            %height=0.65\paperheight,
            xtick=data,
            xticklabels from table={data/perf_vs_oscar.dat}{benchmark},
            xticklabel style={rotate=90},
            yticklabel={\pgfmathparse{\tick*100}\pgfmathprintnumber{\pgfmathresult}\%},
            ymin=0,
            ymax=0.42,
            point meta={y*100},
            %nodes near coords={\pgfmathprintnumber\pgfplotspointmeta\%},
            %nodes near coords align={horizontal},
            bar width=4pt,
            ymajorgrids=true,
            legend style={
                at={(0.15,0.975)},
                anchor=north,
                %legend columns=-1
            },
        	clip=true
        ]
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dune} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dangless} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{oscar_estm} - 1,
                %skip coords between index={15}{100}
            ] {data/perf_vs_oscar.dat};
            
            % Oscar overhead of 447.dealII, which is 90%
            \node at (axis cs:6.1,0.418) [anchor=west] (Aval) {};
            \node at (axis cs:5.5,0.41) [anchor=east] (Aexpl) {\textcolor{brown}{90\%}};
            \draw [->, line width=0.35mm] (Aexpl) -- (Aval);

            % Oscar overhead of 483.xalancbmk, which is 305%
			\node at (axis cs:16.1,0.42) [anchor=west] (Bval) {};
			\node at (axis cs:16.1,0.39) [anchor=east] (Bexpl) {\textcolor{brown}{305\%}};
			\draw [->, line width=0.35mm] (Bexpl) -- (Bval);
            
            \legend{Dune only, Dangless, Oscar}
        \end{axis}
    \end{tikzpicture}
    \label{fig:perf-dune-dangless-oscar}
    \caption{Dune vs Dangless vs Oscar: performance overhead}
\end{figure}

% Memory overhead: Dune vs Dangless vs Oscar
\begin{table}[]
	\centering
	\begin{tabular}{|l|r|r|r|}
		\hline
		\textbf{Benchmark} & \textbf{Dune} & \textbf{Dangless} & \textbf{Oscar} \\ \hline
		401.bzip2          & 0\%         & 0.1\%             & 0\%          \\ \hline
		403.gcc            & 0\%         & 0.5\%             & 5.0\%          \\ \hline
		429.mcf            & 0\%         & 0\%             & 0\%          \\ \hline
		433.milc           & 0\%         & 0.2\%             & 18.0\%          \\ \hline
		444.namd           & 0.7\%         & 2.2\%             & 1.0\%          \\ \hline
		445.gobmk          & 1.0\%         & 3.0\%             & 0\%          \\ \hline
		447.dealII         & 0\%         & {\color{orange} 51.2\%}             & {\color{red} 410.0\%}          \\ \hline
		450.soplex         & 0\%         & 0\%             & {\color{orange} 72.0\%}          \\ \hline
		453.povray         & 0\%         & 11.9\%             & {\color{orange} 40.0\%}          \\ \hline
		456.hmmer          & 0.4\%         & 3.4\%             & {\color{orange} 35.0\%}          \\ \hline
		458.sjeng          & 0.1\%         & 0.4\%             & 0\%          \\ \hline
		462.libquantum     & 0.2\%         & 1.0\%             & 4.0\%          \\ \hline
		464.h264ref        & 0.1\%         & 1.4\%             & 10.0\%          \\ \hline
		470.lbm            & 0.1\%         & 0.2\%             & 0\%          \\ \hline
		473.astar          & 0\%         & 0.3\%             & {\color{orange} 45.0\%}          \\ \hline
		482.sphinx3        & 0.8\%         & 3.3\%             & {\color{red} 400.0\%}          \\ \hline
		483.xalancbmk      & 0\%         & {\color{orange} 94.2\%}             & {\color{red} 180.0\%}          \\ \hline
	\end{tabular}
	\caption{Memory overhead measurements: Dune, Dangless, and Oscar. A value of 0\% indicates no overhead, while a value of 100\% means that memory usage was double that of baseline. Overhead values of 20\% or higher were highlighted in \textcolor{orange}{orange}, while over 100\% are in \textcolor{red}{red}.}
	\label{tab:mem-dune-dangless-oscar}
\end{table}

% Memory overhead: Dune vs Dangless vs Oscar
\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
            scale only axis, % width and height only for the contents, not labels
            width=\textwidth,
            %height=0.65\paperheight,
            xtick=data,
            xticklabels from table={data/mem_vs_oscar.dat}{benchmark},
            xticklabel style={rotate=90},
            yticklabel={\pgfmathparse{\tick*100}\pgfmathprintnumber{\pgfmathresult}\%},
            ymin=0,
            ymax=1,
            point meta={y*100},
            %nodes near coords={\pgfmathprintnumber\pgfplotspointmeta\%},
            %nodes near coords align={horizontal},
            bar width=4pt,
            ymajorgrids=true,
            legend style={
                at={(0.15,0.975)},
                anchor=north,
                %legend columns=-1
            },
        ]
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dune} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{dangless} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            \addplot table [
                x expr=\coordindex,
                y expr=\thisrow{oscar_estm} - 1,
                %skip coords between index={15}{100}
            ] {data/mem_vs_oscar.dat};
            
            % Oscar overhead of 447.dealII, which is 410%
            \node at (axis cs:6.1,0.99) [anchor=west] (Aval) {};
            \node at (axis cs:5.5,0.975) [anchor=east] (Aexpl) {\textcolor{brown}{410\%}};
            \draw [->, line width=0.35mm] (Aexpl) -- (Aval);
            
            % Oscar overhead of 482.sphinx3, which is 400%
            \node at (axis cs:15.1,0.99) [anchor=west] (Bval) {};
            \node at (axis cs:14.5,0.975) [anchor=east] (Bexpl) {\textcolor{brown}{400\%}};
            \draw [->, line width=0.35mm] (Bexpl) -- (Bval);

            % 483.xalancbmk is 180%
            \node at (axis cs:16.2,1.0) [anchor=west] (Cval) {};
            \node at (axis cs:18.0,0.925) [anchor=east] (Cexpl) {\textcolor{brown}{180\%}};
            \draw [->, line width=0.35mm] (Cexpl) -- (Cval);
            
            \legend{Dune only, Dangless, Oscar}
        \end{axis}
    \end{tikzpicture}
    \label{fig:mem-dune-dangless-oscar}
    \caption{Dune vs Dangless vs Oscar: memory overhead}
\end{figure}

\section{Performance analysis}

The overhead posed by Dangless comes from the following primary sources:

\begin{enumerate}
	\item The additional work performed during every memory operation, such as the extra page walk on \lstinline!realloc()! and \lstinline!free()!.
	\item The increased TLB pressure due to each object being mapped to a unique virtual memory page. This results in a significant increase in the number of TLB misses, and so requires a full page-table walk on main memory access. In the case of the Dune-enabled process, the additional two layers of page-tables (the guest page tables and the embedded page tables) make this extra-expensive.
	\item The overhead imposed by the virtualization and Dune, mainly in adding to the cost of system calls when they have to pass through the virtualization boundary. Recall also that Dangless has to ``fix-up'' remapped pointers when they are about to be passed to the host kernel in system call arguments.
\end{enumerate}

In comparison, the overhead added by Oscar and similar user-space techniques, while not suffering from the third reason (the overhead imposed by the virtualization), come from a couple of extra sources:

\begin{enumerate}
	\item Having to perform system calls to create, update, or invalidate the remapped (shadow) virtual memory. System calls are well-known to be expensive, due to the complexity and cost of switching from user code to kernel code, as well as the ``pollution'' of the various hardware caches~\cite{flexsc2010-syscalls}. (Dangless does not need to use system calls, having direct access to the guest page tables.)
	\item The kernel having to track the existence of every virtual memory area used by the process, beyond the data required by the hardware and encoded in the page tables. In Linux, these are stored in a \lstinline!vm_area_struct! object, and are a major source of overhead for Oscar~\cite{oscar2017} and similar technologies. (The additional virtual memory regions created by Dangless are not known to the host kernel, therefore it does not have to keep track of them.)
	\item Having to store the original virtual memory address (the canonical pointer) for each allocation. This means an overhead of 8 bytes on x86-64 per allocation, which turns out to be very significant for applications that allocate a lot of small objects. (Dangless does not need to store the canonical pointer, as it can just get them by performing a page-table walk and relying on Dune's simple virtual memory layout.)
\end{enumerate}

In general, applications (and benchmarks) that perform a large number of memory allocations are going to be the most affected by the overhead imposed by Dangless, Oscar, and similar technologies. To specifically understand the source of overhead and the (often huge) differences between the performance of Dangless and Oscar, we have added extensive statistics to Dangless as well as the reporting of hardware performance metrics.

The most important results are summarized in Table~\ref{tab:perf-analysis-tlb}. Matching this table with the overheads observed, it is clear that benchmarks with few memory allocations (such as bzip2, mcf, namd, gobmk, lbm) suffer very little overhead, confirming our earlier assertion. Further, we can observe a very large increase in the TLB miss rate: however, the TLB miss rate overall still remained very low.

Benchmarks like dealII, sphinx3, and xalancbmk are very allocation-heavy applications, and indeed these represent most of the benchmarks on which Oscar's performance has suffered. This shows how significant overhead is involved in maintaining the Linux kernel's \lstinline!vm_area_struct!-s, as well as having to store the canonical pointers.

\begin{table}[]
	\centering
	\begin{tabular}{|l|r|r|r|r|r|}
		\hline
		\rowcolor[HTML]{EFEFEF} 
		\textbf{Benchmark} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}l@{}}Baseline\\ runtime\\ (seconds)\end{tabular}}} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}l@{}}Allocations\\ / second\end{tabular}}} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}l@{}}Baseline\\ TLB\\ miss rate\end{tabular}}} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}l@{}}Dangless\\ TLB\\ miss rate\end{tabular}}} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}l@{}}Dangless\\ TLB\\ miss rate\\ increase\end{tabular}}} \\ \hline
		401.bzip2          & 1023,816                                                                                                                     & 0,03                                                                                                                 & 0,0006\%                                                                                                                 & 0,0014\%                                                                                                                 & 160,71\%                                                                                                                            \\ \hline
		403.gcc            & 479,326                                                                                                                      & 6.814,98                                                                                                             & 0,0480\%                                                                                                                 & 0,2424\%                                                                                                                 & 405,36\%                                                                                                                            \\ \hline
		429.mcf            & 471,984                                                                                                                      & 0,02                                                                                                                 & 1,2473\%                                                                                                                 & 2,6666\%                                                                                                                 & 113,79\%                                                                                                                            \\ \hline
		433.milc           & 681,409                                                                                                                      & 9,56                                                                                                                 & 0,1702\%                                                                                                                 & 0,3608\%                                                                                                                 & 111,95\%                                                                                                                            \\ \hline
		444.namd           & 821,979                                                                                                                      & 1,62                                                                                                                 & 0,0001\%                                                                                                                 & 0,0003\%                                                                                                                 & 180,71\%                                                                                                                            \\ \hline
		445.gobmk          & 748,740                                                                                                                      & 295,77                                                                                                               & 0,0207\%                                                                                                                 & 0,0327\%                                                                                                                 & 58,16\%                                                                                                                             \\ \hline
		447.dealII         & 1961,820                                                                                                                     & 77.101,32                                                                                                            & 0,0038\%                                                                                                                 & 0,0910\%                                                                                                                 & 2310,45\%                                                                                                                           \\ \hline
		450.soplex         & 558,581                                                                                                                      & 421,05                                                                                                               & 0,0896\%                                                                                                                 & 0,1765\%                                                                                                                 & 97,08\%                                                                                                                             \\ \hline
		453.povray         & 420,569                                                                                                                      & 5.773,20                                                                                                             & 0,0186\%                                                                                                                 & 0,0236\%                                                                                                                 & 26,78\%                                                                                                                             \\ \hline
		456.hmmer          & 1576,148                                                                                                                     & 634,55                                                                                                               & 0,0000\%                                                                                                                 & 0,0007\%                                                                                                                 & 3251,75\%                                                                                                                           \\ \hline
		458.sjeng          & 826,666                                                                                                                      & 0,01                                                                                                                 & 0,0451\%                                                                                                                 & 0,1083\%                                                                                                                 & 140,29\%                                                                                                                            \\ \hline
		462.libquantum     & 691,407                                                                                                                      & 0,23                                                                                                                 & 0,0027\%                                                                                                                 & 0,0049\%                                                                                                                 & 81,05\%                                                                                                                             \\ \hline
		464.h264ref        & 1310,727                                                                                                                     & 79,99                                                                                                                & 0,0096\%                                                                                                                 & 0,0342\%                                                                                                                 & 255,93\%                                                                                                                            \\ \hline
		470.lbm            & 494,989                                                                                                                      & 0,01                                                                                                                 & 0,0261\%                                                                                                                 & 0,0522\%                                                                                                                 & 99,79\%                                                                                                                             \\ \hline
		473.astar          & 786,287                                                                                                                      & 1.420,12                                                                                                             & 0,1248\%                                                                                                                 & 0,5454\%                                                                                                                 & 337,21\%                                                                                                                            \\ \hline
		482.sphinx3        & 1408,159                                                                                                                     & 10.101,62                                                                                                            & 0,0268\%                                                                                                                 & 0,0776\%                                                                                                                 & 189,67\%                                                                                                                            \\ \hline
		483.xalancbmk      & 1287,433                                                                                                                     & 104.980,66                                                                                                           & 0,0385\%                                                                                                                 & 0,6835\%                                                                                                                 & 1675,31\%                                                                                                                           \\ \hline
	\end{tabular}
	\caption{Performance analysis of the SPEC2006 benchmarks, focusing on TLB misses.}
	\label{tab:perf-analysis-tlb}
\end{table}

Finally, the performance impact of having to perform \lstinline!vmcall!s instead of regular system calls, as well as having to ``fix-up'' remapped virtual memory pointers in their arguments is shown to be minimal by Table~\ref{tab:dangless-vmcall-analysis}, as even on benchmarks that perform a large number of system calls (dealII, povray, xalancbmk), the number of pointers we had to rewrite remained low (dealII, xalancbmk) or did not measurably affect performance (povray).

\begin{table}[]
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		\rowcolor[HTML]{EFEFEF} 
		\textbf{Benchmark} & \textbf{\begin{tabular}[c]{@{}l@{}}Baseline\\ run time\\ (seconds)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}VMCalls\\ / second\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}VMCall\\ arg fixups\\ / second\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Dangless\\ runtime\\ overhead\end{tabular}} \\ \hline
		401.bzip2          & 1023,816                                                                         & 0,06                                                                & 0,04                                                                            & 1,30\%                                                                         \\ \hline
		403.gcc            & 479,326                                                                          & 7,12                                                                & 1,04                                                                            & 15,20\%                                                                        \\ \hline
		429.mcf            & 471,984                                                                          & 1,92                                                                & 1,90                                                                            & 11,50\%                                                                        \\ \hline
		433.milc           & 681,409                                                                          & 2,79                                                                & 0,09                                                                            & 10,70\%                                                                        \\ \hline
		444.namd           & 821,979                                                                          & 2,47                                                                & 2,33                                                                            & 0,40\%                                                                         \\ \hline
		445.gobmk          & 748,740                                                                          & 2,86                                                                & 0,49                                                                            & 2,50\%                                                                         \\ \hline
		447.dealII         & 1961,820                                                                         & 24,56                                                               & 4,51                                                                            & 7,40\%                                                                         \\ \hline
		450.soplex         & 558,581                                                                          & 6,65                                                                & 6,56                                                                            & 3,00\%                                                                         \\ \hline
		453.povray         & 420,569                                                                          & 62,85                                                               & 62,55                                                                           & 0,00\%                                                                         \\ \hline
		456.hmmer          & 1576,148                                                                         & 0,05                                                                & 0,05                                                                            & 2,30\%                                                                         \\ \hline
		458.sjeng          & 826,666                                                                          & 4,16                                                                & 0,46                                                                            & 1,10\%                                                                         \\ \hline
		462.libquantum     & 691,407                                                                          & 0,11                                                                & 0,06                                                                            & 0,00\%                                                                         \\ \hline
		464.h264ref        & 1310,727                                                                         & 1,02                                                                & 0,43                                                                            & 0,00\%                                                                         \\ \hline
		470.lbm            & 494,989                                                                          & 1,40                                                                & 1,38                                                                            & 0,30\%                                                                         \\ \hline
		473.astar          & 786,287                                                                          & 1,36                                                                & 0,08                                                                            & 24,60\%                                                                        \\ \hline
		482.sphinx3        & 1408,159                                                                         & 4,72                                                                & 4,34                                                                            & 3,00\%                                                                         \\ \hline
		483.xalancbmk      & 1287,433                                                                         & 15,22                                                               & 12,86                                                                           & 19,80\%                                                                        \\ \hline
	\end{tabular}
	\caption{Performance overhead analysis of \texttt{vmcall}s with Dangless.}
	\label{tab:dangless-vmcall-analysis}
\end{table}

\section{Virtual memory exhaustion}
\label{sec:virtmem-exhaustion}

Let us recall that Dangless, in its current implementation, does not ever reclaim virtual memory. Once a page has been used to shadow an allocated object, it is never reused, meaning that eventually, virtual memory will run out, and we will no longer be able to re-map the allocations as they happen.

Dangless is focused on the x86-64 architecture, which uses 48 bits (out of the 64 available) for virtual memory addresses, meaning that the entire address space is 256 terabytes big. Assuming a worst-case scenario of many small object allocations (since each need to be remapped on a unique virtual memory page, regardless of whether it is 32 bytes or 4 kilobytes), this would be sufficient for 68 719 476 736 ($= 2^{36} = 0x1000000000$) allocations. Let us take into account that normal, non-shadow memory also needs space, and reserve a full 1 terabyte for them (or 268 435 456 pages), leaving us with space for 68 451 041 280 shadow pages.

Looking at the most allocation-heavy SPEC2006 benchmarks as seen on Table~\ref{tab:perf-analysis-tlb}, xalancbmk performs almost 150 000 allocations per second on average. With the calculated virtual memory available, this means that it would be able to keep running at this pace for 456 340 seconds, or almost 127 hours. (The benchmark, however, on my machine completes in just 1287 seconds.) The second most intensive benchmark, dealII, performs 77 100 allocations every second (on average), so it run continuously for almost double of that time. These benchmarks are also highly unusual in their memory intensity.

These numbers go to show that while not reclaiming virtual memory is certainly wasteful and eventually leads to Dangless being unable to protect further allocations, this limitation is not necessarily crippling. Nonetheless, this is the primary opportunity for improvement on its design and implementation.

\section{Summary of contributions}

%\todo{Most of this is now mentioned in Performance Analysis - is it bad to talk about it again? A summary like this makes sense, I believe.}

Dangless MAlloc demonstrates the power of process-level, hardware-assisted virtualization and its use for hardening processes against bugs and malicious users without having to pay the usual performance penalties. This makes the approach of creating and destroying shadow virtual pages, used by previous work such as Oscar~\cite{oscar2017}, noticeably cheaper, without making the design significantly more complex. (Although the implementation does take somewhat more effort, due to the virtualization making a Dune-enabled application more difficult to debug.)

Specifically, by running the process in a virtualized environment, Dangless does not have to perform a system call for managing the remapped (shadow) virtual memory, being able to manipulate the (guest) page tables directly -- at the minor cost of having to pass all normal system calls to the host kernel as measured by the original Dune research paper~\cite{dune-paper}.

Because these extra virtual memory mappings only exist in the guest system, the hosting Linux kernel is not aware of them, and does not have to maintain a \lstinline!vm_area_struct! structure for each of them -- something that is a source of significant overhead in similar approaches~\cite{oscar2017}. This comes at the cost of having to ``fix-up'' remapped pointers in system call arguments before they can be passed on the host kernel, but in practice this was not found to have noticeable performance implications.

Finally, Dangless does not have to store the canonical memory address of each allocation, because the virtual memory layout of Dune is very simple and predictable, allowing us to compute the canonical virtual addresses based on the physical ones. This does add the overhead of a single page walk to determine the physical memory address for every allocation management operation such as \lstinline!realloc()! and \lstinline!free()!, but the cost of these is insignificant compared to cost of prior approaches. Therefore, the only memory overhead posed by Dangless is the extra page tables used to encode these virtual memory mappings.

\section{Limitations and improvement opportunities}

Dangless Malloc was created as a proof of concept, and its implementation could be improved in various ways.

For instance, the \lstinline!realloc()! implementation is not optimal: even if the system allocator was unable to perform an in-place reallocation, we could still potentially do so with the remapped pages, if the virtual memory region following them is available. Care should only be taken to modify the page table entry of each of the old virtual page mappings to point to the new physical addresses.

Similarly, there's no real reason why Dangless is currently unable to handle the system allocator returning a virtual memory region that is not backed by contiguous guest physical memory.

As discussed earlier, Dangless could be smarter about its virtual memory auto-dedication logic, for example by acquiring unused virtual memory regions on-demand. We could also be using hugepages for the shadow virtual memory when the allocation size is greater than 2 MB or 1 GB.

In order to make it easier to incorporate Dangless into projects, it should support installation and exporting its CMake targets.

Major improvement opportunities would be supporting multi-threaded applications, after investigating Dune's state of support for it, and supporting the \lstinline!clone()! system call.

Finally, some mechanism for reclaiming virtual memory once we can reasonably guarantee the absence of pointers to them would ensure that we never run out of virtual memory even in long-running applications such as web servers. In order to measure the impact of Dangless on these types of workloads, further performance testing should be performed.

\section{Conclusion}

Memory errors have plagued software developers and users alike since the day computers became widespread. After decades of research and development, they remain a major source of bugs and security vulnerabilities. While tooling to help avoid and quickly diagnose such problems underwent serious development, they remain too expensive and complicated to use outside of development and testing. As the Internet today represents an invaluable global resource, overseeing a myriad of functions, security vulnerabilities created by such errors become more critical than ever.

Temporal memory errors such as those arising from dangling pointers represent a difficult problem to solve using traditional means, as they are difficult to identify using static analysis, and even if found through other means, remains difficult to diagnose. This necessitated the development of tools that were specialized for this task.

In this thesis, I have presented an improvement over previous approaches by utilizing light-weight process-based virtualization aided by Dune. This enabled the implementation of well-known techniques, such as using virtual memory remapping (or shadow virtual memory) in a manner that comes at a significant lower performance cost.

While further work is definitely needed to explore the topic, Dangless represents a major step towards a world where we can continue using low-level, ``unsafe'' programming languages without sacrificing memory safety.
